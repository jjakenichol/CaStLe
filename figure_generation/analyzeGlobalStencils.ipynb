{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import clif.preprocessing as cpp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import xarray as xr\n",
    "\n",
    "from tigramite import data_processing as pp\n",
    "from tigramite import plotting as tp\n",
    "from tigramite.independence_tests.parcorr import ParCorr\n",
    "from tigramite.pcmci import PCMCI\n",
    "from tigramite.toymodels import structural_causal_processes\n",
    "\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "from matplotlib.artist import Artist\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.expanduser(\"~\") + \"../src/\")\n",
    ")\n",
    "import stencil_functions as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_release_dir = \"/path/to/benchmark/data/HSW/release_011423/\"\n",
    "mar_release_dir = \"/path/to/benchmark/data/HSW/release_030123/\"\n",
    "\n",
    "ens = \"ens01\"\n",
    "# source_dir = os.path.join(jan_release_dir, ens)\n",
    "source_dir = os.path.join(mar_release_dir, ens)\n",
    "\n",
    "AODH0_SOURCE = os.path.join(source_dir, \"AOD.nc\")\n",
    "SH0_SOURCE = os.path.join(source_dir, \"SULFATE.nc\")\n",
    "UH0_SOURCE = os.path.join(source_dir, \"U.nc\")\n",
    "VH0_SOURCE = os.path.join(source_dir, \"V.nc\")\n",
    "\n",
    "ds = xr.open_mfdataset([AODH0_SOURCE, SH0_SOURCE, UH0_SOURCE, VH0_SOURCE])\n",
    "\n",
    "# Remake longitude coords to be -180 to 180 instead of 0 to 360\n",
    "import dask\n",
    "with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
    "    ds.coords['lon'] = (ds.coords['lon'] + 180) % 360 - 180\n",
    "    ds = ds.sortby(ds.lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (ds[\"AOD\"].values!=0)\n",
    "onset = np.min(np.where(mask.any(axis=0), mask.argmax(axis=0), -1))\n",
    "onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sulfate_avg = ds[\"SULFATE\"].mean(dim=['time', 'lat', 'lon'])\n",
    "\n",
    "# Convert the threshold to the same units as your data (kg/kg)\n",
    "threshold = 5e-9  # 5 micrograms/microgram in kg/kg\n",
    "\n",
    "# Compute the condition to find levels where the average sulfate concentration is greater than the threshold\n",
    "condition = (sulfate_avg > threshold).compute()\n",
    "\n",
    "# Use the computed condition to filter levels\n",
    "levels_above_threshold = sulfate_avg['lev'].where(condition, drop=True)\n",
    "\n",
    "# Now, plot 'lev' on the X-axis and the averaged sulfate concentration on the Y-axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sulfate_avg['lev'], sulfate_avg, label='Sulfate Concentration')\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label='Threshold (5 micrograms/microgram)')\n",
    "plt.xlabel('Level (lev)')\n",
    "plt.ylabel('Sulfate Concentration (kg/kg)')\n",
    "plt.title('Sulfate Concentration Across Levels')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print the levels above the threshold\n",
    "print(\"Levels above the threshold (5 micrograms/microgram):\", levels_above_threshold.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sulf_vals = sulfate_avg.values\n",
    "np.min(avg_sulf_vals), np.max(avg_sulf_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the AUC for the entire curve\n",
    "auc_total = np.trapz(sulfate_avg.values, x=sulfate_avg['lev'].values)\n",
    "print(\"Total AUC:\", auc_total)\n",
    "\n",
    "# To compute the AUC for the curve above the threshold, we first need to filter the data\n",
    "# We'll use the 'condition' variable which contains True for levels above the threshold\n",
    "sulfate_above_threshold = sulfate_avg.where(condition, drop=True)\n",
    "\n",
    "auc_above_threshold = np.trapz(sulfate_above_threshold.values, x=sulfate_above_threshold['lev'].values)\n",
    "print(\"AUC above the threshold:\", auc_above_threshold)\n",
    "\n",
    "percentage_above_threshold = (auc_above_threshold / auc_total) * 100\n",
    "\n",
    "print(f\"Percentage of sulfate in the AUC of the interval above the threshold compared to the total: {percentage_above_threshold:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcorr = ParCorr(significance=\"analytic\")\n",
    "\n",
    "def linear(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = [\"NW\", \"N\", \"NE\", \"W\", \"Self\", \"E\", \"SW\", \"S\", \"SE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dimension = 10\n",
    "\n",
    "lat_min = -20\n",
    "lat_max = 50\n",
    "lon_min = 55\n",
    "lon_max = 125\n",
    "\n",
    "lat_bounds = [((lat - grid_dimension), lat) for lat in range(lat_min + grid_dimension, lat_max + grid_dimension, grid_dimension)]\n",
    "lat_bounds.reverse()\n",
    "lon_bounds = [(lon - grid_dimension, lon) for lon in range(lon_min + grid_dimension, lon_max + grid_dimension, grid_dimension)]\n",
    "lon_bounds = [(lon[0], lon[1]) for lon in lon_bounds]\n",
    "lat_bounds, lon_bounds, len(lon_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    \"\"\"\n",
    "    Truncates a colormap by specifying the start and end point on a scale of 0 to 1.\n",
    "    :param cmap: Original colormap instance.\n",
    "    :param minval: Start point (default is 0.0).\n",
    "    :param maxval: End point (default is 1.0).\n",
    "    :param n: Number of RGB quantization levels (default is 100).\n",
    "    :return: New colormap instance truncated between minval and maxval.\n",
    "    \"\"\"\n",
    "    new_cmap = LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap\n",
    "\n",
    "original_cmap = plt.get_cmap('viridis')\n",
    "truncated_heatmap_cmap = truncate_colormap(original_cmap, minval=0.0, maxval=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(len(lon_bounds)*5,len(lat_bounds)*5))\n",
    "total_time = 0\n",
    "\n",
    "# plot options:\n",
    "heatmap_flag = True\n",
    "coastlines_flag = True\n",
    "wind_flag = False\n",
    "smart_wind_calc = True\n",
    "causal_flag = True\n",
    "\n",
    "start_index = 366\n",
    "stop_index = 400 # 400, 425, 450\n",
    "max_stop_index = stop_index#450\n",
    "clipper = cpp.ClipTransform(dims=[\"lat\", \"lon\"], bounds=[(lat_min, lat_max), (lon_min, lon_max)])\n",
    "spatial_TS_total = np.mean(clipper.fit_transform(ds[\"AOD\"]), axis=(1,2))[start_index:max_stop_index].values\n",
    "vmin = spatial_TS_total.min()\n",
    "vmax = spatial_TS_total.max()\n",
    "\n",
    "idx = 1\n",
    "for lat_bound in lat_bounds:\n",
    "    print(\"Latitudes:{}\".format(lat_bound))\n",
    "    for lon_bound in lon_bounds:\n",
    "        print(\"Longitudes:{}\".format(lon_bound))\n",
    "        with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "            clipper = cpp.ClipTransform(dims=[\"lat\", \"lon\"], bounds=[lat_bound, lon_bound])\n",
    "            AODH0_grid = clipper.fit_transform(ds[\"AOD\"])\n",
    "            AODH0_array = AODH0_grid.values\n",
    "            if wind_flag:\n",
    "                # Get wind field data\n",
    "                UH0_grid = clipper.fit_transform(ds[\"U\"])\n",
    "                VH0_grid = clipper.fit_transform(ds[\"V\"])\n",
    "                if smart_wind_calc:\n",
    "                    SH0_grid = clipper.fit_transform(ds[\"SULFATE\"])\n",
    "                    S_bulk_levs = SH0_grid.mean(dim=[\"lat\", \"lon\", \"time\"]).values\n",
    "                    u_S_bulk = UH0_grid.sel(lev=np.where(S_bulk_levs >= 0.000000005)[0], method=\"nearest\")\n",
    "                    v_S_bulk = VH0_grid.sel(lev=np.where(S_bulk_levs >= 0.000000005)[0], method=\"nearest\")\n",
    "                else:\n",
    "                    u_S_bulk = UH0_grid\n",
    "                    v_S_bulk = VH0_grid\n",
    "                    \n",
    "\n",
    "                lat = VH0_grid[\"lat\"]\n",
    "                lon = VH0_grid[\"lon\"]\n",
    "                lon, lat = np.meshgrid(lon, lat)\n",
    "                full_lon, full_lat = np.meshgrid(ds[\"U\"][\"lon\"], ds[\"U\"][\"lat\"])\n",
    "\n",
    "\n",
    "        AODH0 = AODH0_array\n",
    "        AODH0 = np.transpose(AODH0[start_index:stop_index], (1, 2, 0))\n",
    "        GRID_SIZE = AODH0.shape[0]\n",
    "\n",
    "        if causal_flag:\n",
    "            start_time = time.time()\n",
    "            pc_alpha=0.00001  # 0.00001\n",
    "            castle_corr_threshold = 0.35\n",
    "            graph, v_matrix = sf.CaStLe(data=AODH0, cond_ind_test=parcorr, pc_alpha=pc_alpha, rows_inverted=False, dependence_threshold=castle_corr_threshold, dependencies_wrap=False)\n",
    "            full_graph, full_v_matrix = sf.get_expanded_graph_from_stencil_graph(graph, v_matrix, GRID_SIZE, include_lagzero_parents=False, wrapping=False)\n",
    "\n",
    "            end_time = time.time()\n",
    "            total_time += (end_time - start_time)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##### PLOTTING #####\n",
    "        if heatmap_flag:\n",
    "            ax = fig.add_subplot(len(lat_bounds), len(lon_bounds), idx, projection=ccrs.PlateCarree())\n",
    "            heatmap_data = np.mean(AODH0_array[start_index:stop_index, :, :], axis=0)\n",
    "            extent = (lon_bound[0], lon_bound[1], lat_bound[0], lat_bound[1])\n",
    "            padded_extent = (lon_bound[0]-1, lon_bound[1]+1, lat_bound[0]-1, lat_bound[1]+1)\n",
    "            _lat = np.linspace(extent[0],extent[1],heatmap_data.shape[0])\n",
    "            _lon = np.linspace(extent[2],extent[3],heatmap_data.shape[1])\n",
    "            Lat,Lon = np.meshgrid(_lat,_lon)\n",
    "            ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "            hm = ax.pcolormesh(Lat, Lon, heatmap_data, vmin=vmin, vmax=vmax, cmap=truncated_heatmap_cmap, snap=False, alpha=1, rasterized=False)#, edgecolor='k')\n",
    "            if coastlines_flag:\n",
    "                ax.coastlines(linewidth=2, color='black')\n",
    "\n",
    "        # Plot triangle over pinatubo\n",
    "        pinatubo_coords = (15, 120)\n",
    "        if lat_bound[0] <= pinatubo_coords[0] <= lat_bound[1]:\n",
    "            if lon_bound[0] <= pinatubo_coords[1] <= lon_bound[1]:\n",
    "                offset = 3\n",
    "                tri_vertices = [\n",
    "                    (pinatubo_coords[1], pinatubo_coords[0] + offset),\n",
    "                    (pinatubo_coords[1] - offset, pinatubo_coords[0] - offset),\n",
    "                    (pinatubo_coords[1] + offset, pinatubo_coords[0] - offset),\n",
    "                ]\n",
    "                tri_color = 'white'\n",
    "                ax.add_patch(plt.Polygon(tri_vertices, color=tri_color, fill=True))\n",
    "    \n",
    "\n",
    "        if wind_flag:\n",
    "            ax = fig.add_subplot(len(lat_bounds), len(lon_bounds), idx, projection=ccrs.PlateCarree())\n",
    "            time_subselect = xr.DataArray(np.arange(start_index, stop_index), dims=\"time\")\n",
    "            u = u_S_bulk.mean(dim=\"lev\").isel(time=time_subselect).mean(dim=\"time\")\n",
    "            v = v_S_bulk.mean(dim=\"lev\").isel(time=time_subselect).mean(dim=\"time\")\n",
    "            step=1\n",
    "            q = ax.quiver(\n",
    "                lon[::step, ::step],\n",
    "                lat[::step, ::step],\n",
    "                u[::step, ::step],\n",
    "                v[::step, ::step],\n",
    "                angles='xy',\n",
    "                scale_units='xy',\n",
    "                scale=6,\n",
    "                width=0.02,\n",
    "                color=\"green\",\n",
    "                transform=ccrs.PlateCarree()\n",
    "            )\n",
    "            ax.patch.set_alpha(0)\n",
    "            ax.axis('off')\n",
    "\n",
    "        if causal_flag:\n",
    "            ax1 = fig.add_subplot(len(lat_bounds), len(lon_bounds), idx, projection=ccrs.PlateCarree())\n",
    "            # Full graph:\n",
    "            x_pos = list(np.array([[i for i in range(GRID_SIZE)] for j in range(GRID_SIZE)]).flatten())\n",
    "            y_pos = [i for i in range(GRID_SIZE) for j in range(GRID_SIZE)]\n",
    "            y_pos.reverse()\n",
    "            node_positions = {\n",
    "                \"x\": x_pos,\n",
    "                \"y\": y_pos,\n",
    "            }\n",
    "            cmap_N = 256\n",
    "            white_vals = np.ones((cmap_N, 4))\n",
    "            black_vals = np.zeros((cmap_N, 4))\n",
    "            white_cmap = ListedColormap(white_vals)\n",
    "            black_cmap = ListedColormap(black_vals)\n",
    "            tp.plot_graph(\n",
    "                fig_ax=(fig, ax1),\n",
    "                val_matrix=full_v_matrix.round(),\n",
    "                graph=full_graph,\n",
    "                # graph=graph,\n",
    "                link_label_fontsize=0.,\n",
    "                head_width=3, # 5\n",
    "                head_length=2, # 3\n",
    "                tail_width=0.5, # 1\n",
    "                cmap_edges=white_cmap,\n",
    "                cmap_nodes=\"binary\",\n",
    "                show_colorbar=False,\n",
    "                var_names=[\"\"]*GRID_SIZE**2,\n",
    "                node_pos=node_positions,\n",
    "            )\n",
    "            # Remove link labels which always have \"1\"\n",
    "            for child in ax1.get_children():\n",
    "                if isinstance(child, matplotlib.text.Text):\n",
    "                    if child.get_text() == \"1\":\n",
    "                        Artist.set_visible(child, False)\n",
    "            ax1.patch.set_alpha(0)\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "fig.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = f\"HSW_blockSize{grid_dimension}_depThresh{castle_corr_threshold}_lats{(lat_min,lat_max)}_lons{(lon_min,lon_max)}_timestart{start_index}_timeend{stop_index}.pdf\"\n",
    "fig.savefig(figure_name, bbox_inches='tight')\n",
    "figure_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a new figure and replot the colorbar there\n",
    "fig,ax = plt.subplots(figsize=(10,2))\n",
    "cbar = plt.colorbar(hm,ax=ax, location=\"bottom\")\n",
    "cmap_label_fontsize=20\n",
    "cbar.ax.tick_params(labelsize=cmap_label_fontsize)\n",
    "cbar.set_label(label=\"Aerosol Optical Depth\", size=cmap_label_fontsize,)\n",
    "ax.remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax1 = fig.add_subplot(2,2,1, projection=ccrs.PlateCarree())\n",
    "ax2 = fig.add_subplot(2,2,2, projection=ccrs.PlateCarree())\n",
    "ax3 = fig.add_subplot(2,2,3, projection=ccrs.PlateCarree())\n",
    "ax4 = fig.add_subplot(2,2,4, projection=ccrs.PlateCarree())\n",
    "\n",
    "ax1.set_extent([0, 90, 90, 0], crs=ccrs.PlateCarree())\n",
    "ax2.set_extent([90, 180, 90, 0], crs=ccrs.PlateCarree())\n",
    "ax3.set_extent([0, 90, 0, -90], crs=ccrs.PlateCarree())\n",
    "ax4.set_extent([90, 180, 0, -90], crs=ccrs.PlateCarree())\n",
    "\n",
    "pinatubo_coords = (15, 120)\n",
    "offset = 4\n",
    "tri_vertices = [\n",
    "    (pinatubo_coords[1], pinatubo_coords[0] + offset),\n",
    "    (pinatubo_coords[1] - offset, pinatubo_coords[0] - offset),\n",
    "    (pinatubo_coords[1] + offset, pinatubo_coords[0] - offset),\n",
    "]\n",
    "tri_color = 'red'\n",
    "ax2.add_patch(plt.Polygon(tri_vertices, color=tri_color, fill=True))\n",
    "\n",
    "ax1.coastlines()\n",
    "ax2.coastlines()\n",
    "ax3.coastlines()\n",
    "ax4.coastlines()\n",
    "\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(800, 4801, 400):\n",
    "    clipper = cpp.ClipTransform(dims=[\"lat\", \"lon\"], bounds=[(10, 20), (70, 80)])\n",
    "    AODH0_grid = clipper.fit_transform(ds[\"AOD\"])\n",
    "    SH0_grid = clipper.fit_transform(ds[\"SULFATE\"])\n",
    "    UH0_grid = clipper.fit_transform(ds[\"U\"])\n",
    "    VH0_grid = clipper.fit_transform(ds[\"V\"])\n",
    "\n",
    "    lat = VH0_grid[\"lat\"]\n",
    "    lon = VH0_grid[\"lon\"]\n",
    "    lon, lat = np.meshgrid(lon, lat)\n",
    "\n",
    "    AODH0_array = AODH0_grid.values\n",
    "\n",
    "    # Get wind field data\n",
    "    S_bulk_levs = SH0_grid.mean(dim=[\"lat\", \"lon\", \"time\"]).values\n",
    "    u_S_bulk = UH0_grid.sel(lev=np.where(S_bulk_levs >= 0.000000005)[0], method=\"nearest\")\n",
    "    v_S_bulk = VH0_grid.sel(lev=np.where(S_bulk_levs >= 0.000000005)[0], method=\"nearest\")\n",
    "\n",
    "    start_index = 400\n",
    "    stop_index = t\n",
    "\n",
    "    AODH0 = AODH0_array.copy()\n",
    "    AODH0 = np.transpose(AODH0[start_index:stop_index], (1, 2, 0))\n",
    "\n",
    "    GRID_SIZE = AODH0.shape[0]\n",
    "\n",
    "\n",
    "    concatenated_data = sf.concatenate_timeseries_nonwrapping(AODH0, True)\n",
    "    pcmci_df = pp.DataFrame(concatenated_data[:, :9])\n",
    "\n",
    "    pcmci = PCMCI(dataframe=pcmci_df, cond_ind_test=parcorr, verbosity=1)\n",
    "\n",
    "\n",
    "    selected_links=None\n",
    "    link_assumptions=None\n",
    "    tau_min=1\n",
    "    tau_max=1\n",
    "    save_iterations=False\n",
    "    pc_alpha=0.00001\n",
    "    max_conds_dim=None\n",
    "    max_combinations=1\n",
    "\n",
    "\n",
    "    # Create an internal copy of pc_alpha\n",
    "    _int_pc_alpha = deepcopy(pc_alpha)\n",
    "    # Check if we are selecting an optimal alpha value\n",
    "    select_optimal_alpha = True\n",
    "    # Set the default values for pc_alpha\n",
    "    if _int_pc_alpha is None:\n",
    "        _int_pc_alpha = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "    elif not isinstance(_int_pc_alpha, (list, tuple, np.ndarray)):\n",
    "        _int_pc_alpha = [_int_pc_alpha]\n",
    "        select_optimal_alpha = False\n",
    "    # Check the limits on tau_min\n",
    "    pcmci._check_tau_limits(tau_min, tau_max)\n",
    "    tau_min = max(1, tau_min)\n",
    "    # Check that the maximum combinations variable is correct\n",
    "    if max_combinations <= 0:\n",
    "        raise ValueError(\"max_combinations must be > 0\")\n",
    "    # Implement defaultdict for all pval_max, val_max, and iterations\n",
    "    pval_max = defaultdict(dict)\n",
    "    val_min = defaultdict(dict)\n",
    "    iterations = defaultdict(dict)\n",
    "\n",
    "\n",
    "    # Set the selected links\n",
    "    # _int_sel_links = self._set_sel_links(selected_links, tau_min, tau_max,\n",
    "    #                                      remove_contemp=True)\n",
    "    _int_link_assumptions = pcmci._set_link_assumptions(link_assumptions, \n",
    "        tau_min, tau_max, remove_contemp=True)\n",
    "\n",
    "    # Initialize all parents\n",
    "    all_parents = dict()\n",
    "    # Set the maximum condition dimension\n",
    "    max_conds_dim = pcmci._set_max_condition_dim(max_conds_dim,\n",
    "                                                tau_min, tau_max)\n",
    "\n",
    "\n",
    "    all_parents = {i: {'parents': [],\n",
    "        'val_min': {(j, -1): 0 for j in range(9)}, \n",
    "        'pval_max': {(k, -1): 1 for k in range(9)},\n",
    "        'iterations':{}} for i in range(9)}\n",
    "    all_parents[4] = pcmci._run_pc_stable_single(4, link_assumptions_j=_int_link_assumptions[4], pc_alpha=pc_alpha)\n",
    "\n",
    "\n",
    "    # Make SCM and val_matrix for plotting\n",
    "    dependence_threshold = 0.001\n",
    "    SCM = {}\n",
    "\n",
    "    for key in all_parents.keys():\n",
    "        SCM[key] = []\n",
    "        parents_list = [parent[0] for parent in all_parents[key][\"parents\"]]\n",
    "        for parent in parents_list:\n",
    "            coefficient = all_parents[key][\"val_min\"][(parent, -1)]\n",
    "            if abs(coefficient) < dependence_threshold:\n",
    "                coefficient = 0\n",
    "            SCM[key].append(((parent, -1), coefficient, linear))\n",
    "\n",
    "    graph = structural_causal_processes.links_to_graph(SCM)\n",
    "\n",
    "\n",
    "    v_matrix = np.zeros(graph.shape)\n",
    "    for row in range(v_matrix.shape[0]):\n",
    "        if len(SCM[row]) != 0:\n",
    "            for dependence in SCM[row]:\n",
    "                coefficient = dependence[1]\n",
    "                v_matrix[dependence[0][0], row, 1] = coefficient\n",
    "\n",
    "    parents = sf.get_parents(graph, val_matrix=v_matrix, include_lagzero_parents=True, output_val_matrix=True)\n",
    "    reconstructed_full_graph, reconst_val_matrix = sf.get_expanded_graph(parents[4], 5, wrapping=False)\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "    ax1 = fig.add_subplot(1, 3, 1)\n",
    "    x_pos = list(np.array([[i for i in range(3)] for j in range(3)]).flatten())\n",
    "    y_pos = [i for i in range(3) for j in range(3)]\n",
    "    y_pos.reverse()\n",
    "    node_positions = {\n",
    "        \"x\": x_pos,\n",
    "        \"y\": y_pos,\n",
    "    }\n",
    "    tp.plot_graph(\n",
    "        fig_ax=(fig, ax1),\n",
    "        val_matrix=v_matrix,\n",
    "        graph=graph,\n",
    "        node_pos=node_positions,\n",
    "        link_colorbar_label=\"cross-MCI\",\n",
    "        node_colorbar_label=\"auto-MCI\",\n",
    "    )\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 3, 2, projection=ccrs.PlateCarree())\n",
    "    time_subselect = xr.DataArray(np.arange(start_index, stop_index), dims=\"time\")\n",
    "    u = u_S_bulk.mean(dim=\"lev\").isel(time=time_subselect).mean(dim=\"time\")\n",
    "    v = v_S_bulk.mean(dim=\"lev\").isel(time=time_subselect).mean(dim=\"time\")\n",
    "    q = ax2.quiver(lon, lat, u, v, transform=ccrs.PlateCarree())\n",
    "    ax2.quiverkey(q, X=0.3, Y=1.05, U=15,\n",
    "             label='Quiver key, length = 50', labelpos='E')\n",
    "\n",
    "    ax3 = fig.add_subplot(1, 3, 3)\n",
    "    plt.plot(np.mean(AODH0_array[start_index:stop_index, :, :], axis=(1,2)))\n",
    "    ax3.set_ylabel(\"AOD\")\n",
    "    ax3.set_xlabel(\"Time step\")\n",
    "\n",
    "    plt.title(\"Timesteps {}-{}\".format(start_index, stop_index))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"grid_dimension={(lon_max - lon_min)/2}x{(lat_max - lat_min)/2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot options:\n",
    "heatmap_flag = True\n",
    "coastlines_flag = True\n",
    "wind_flag = False\n",
    "smart_wind_calc = False\n",
    "causal_flag = True\n",
    "\n",
    "lat_bound = (lat_min, lat_max)#(-20, 60)#(0, 20)\n",
    "lon_bound = (lon_min, lon_max)#(30, 110)#(90, 110)\n",
    "lat_bounds = [lat_bound]\n",
    "lon_bounds = [lon_bound]\n",
    "lat_diff = lat_bound[1] - lat_bound[0]\n",
    "lon_diff = lon_bound[1] - lon_bound[0]\n",
    "pc_alpha = 0.00001\n",
    "pval_threshold = 0.05\n",
    "\n",
    "start_index = 366\n",
    "stop_index = 400\n",
    "max_stop_index = stop_index\n",
    "clipper = cpp.ClipTransform(dims=[\"lat\", \"lon\"], bounds=[(lat_min, lat_max), (lon_min, lon_max)])\n",
    "spatial_TS_total = np.mean(clipper.fit_transform(ds[\"AOD\"]), axis=(1,2))[start_index:max_stop_index].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "    clipper = cpp.ClipTransform(dims=[\"lat\", \"lon\"], bounds=[lat_bound, lon_bound])\n",
    "    AODH0_grid = clipper.fit_transform(ds[\"AOD\"])\n",
    "    AODH0_array = AODH0_grid.values\n",
    "    if wind_flag:\n",
    "        # Get wind field data\n",
    "        UH0_grid = clipper.fit_transform(ds[\"U\"])\n",
    "        VH0_grid = clipper.fit_transform(ds[\"V\"])\n",
    "        if smart_wind_calc:\n",
    "            SH0_grid = clipper.fit_transform(ds[\"SULFATE\"])\n",
    "            S_bulk_levs = SH0_grid.mean(dim=[\"lat\", \"lon\", \"time\"]).values\n",
    "            u_S_bulk = UH0_grid.sel(lev=np.where(S_bulk_levs >= 0.000000005)[0], method=\"nearest\")\n",
    "            v_S_bulk = VH0_grid.sel(lev=np.where(S_bulk_levs >= 0.000000005)[0], method=\"nearest\")\n",
    "        else:\n",
    "            u_S_bulk = UH0_grid\n",
    "            v_S_bulk = VH0_grid\n",
    "            \n",
    "\n",
    "        lat = VH0_grid[\"lat\"]\n",
    "        lon = VH0_grid[\"lon\"]\n",
    "        lon, lat = np.meshgrid(lon, lat)\n",
    "        full_lon, full_lat = np.meshgrid(ds[\"U\"][\"lon\"], ds[\"U\"][\"lat\"])\n",
    "\n",
    "\n",
    "AODH0 = AODH0_array\n",
    "AODH0 = np.transpose(AODH0[start_index:stop_index], (1, 2, 0))\n",
    "GRID_SIZE = AODH0.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if causal_flag:\n",
    "    data = AODH0.reshape(AODH0.shape[0]*AODH0.shape[1], AODH0.shape[2]).transpose()\n",
    "    pcmci_df = pp.DataFrame(data)\n",
    "\n",
    "    parcorr = ParCorr(significance=\"analytic\")\n",
    "    start_time = time.time()\n",
    "    graph, val_matrix = sf.PC(data, parcorr, min_tau=1, max_tau=1, pc_alpha=pc_alpha, pval_threshold=pval_threshold)\n",
    "    time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f\"PC-HSW_depThresh{pval_threshold}_lats{lat_bound}_lons{lon_bound}_timestart{start_index}_timeend{stop_index}.npz\"\n",
    "\n",
    "if not os.path.exists(fname):\n",
    "    np.savez(\n",
    "        fname,\n",
    "        graph=graph,\n",
    "        val_matrix=val_matrix,\n",
    "    )\n",
    "    print(f\"Data saved to {fname}\")\n",
    "else:\n",
    "    loaded_data = np.load(fname)\n",
    "    graph = loaded_data[\"graph\"]\n",
    "    val_matrix = loaded_data[\"val_matrix\"]\n",
    "    print(f\"Data loaded from {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_bound, lat_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask where val_matrix elements are >= 0.5\n",
    "mask = val_matrix >= 0.7\n",
    "\n",
    "# Use np.where to replace non-matching elements\n",
    "graph = np.where(mask, graph, \"\")  # Replace non-matching elements with empty strings in graph\n",
    "val_matrix = np.where(mask, val_matrix, 0)  # Replace non-matching elements with 0 in val_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PLOTTING #####\n",
    "fig = plt.figure(figsize=(lon_diff,lat_diff))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "if heatmap_flag:\n",
    "    heatmap_data = np.mean(AODH0_array[start_index:stop_index, :, :], axis=0)\n",
    "    extent = (lon_bound[0], lon_bound[1], lat_bound[0], lat_bound[1])\n",
    "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "    if coastlines_flag:\n",
    "        ax.coastlines(linewidth=2, color='black')\n",
    "    # Generate edges for Lat and Lon arrays\n",
    "    _lat_edges = np.linspace(extent[2], extent[3], heatmap_data.shape[0] + 1)\n",
    "    _lon_edges = np.linspace(extent[0], extent[1], heatmap_data.shape[1] + 1)\n",
    "\n",
    "    # Create meshgrid from edges\n",
    "    Lat_edges, Lon_edges = np.meshgrid(_lat_edges, _lon_edges, indexing='ij')\n",
    "\n",
    "    # Now use Lat_edges and Lon_edges in pcolormesh\n",
    "    hm = ax.pcolormesh(Lon_edges, Lat_edges, heatmap_data, vmin=vmin, vmax=vmax, cmap=truncated_heatmap_cmap, snap=False, alpha=1, rasterized=False)\n",
    "    ax.patch.set_alpha(0)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Plot triangle over pinatubo\n",
    "pinatubo_coords = (15, 120)\n",
    "if lat_bound[0] <= pinatubo_coords[0] <= lat_bound[1]:\n",
    "    if lon_bound[0] <= pinatubo_coords[1] <= lon_bound[1]:\n",
    "        offset = 3\n",
    "        tri_vertices = [\n",
    "            (pinatubo_coords[1], pinatubo_coords[0] + offset),\n",
    "            (pinatubo_coords[1] - offset, pinatubo_coords[0] - offset),\n",
    "            (pinatubo_coords[1] + offset, pinatubo_coords[0] - offset),\n",
    "        ]\n",
    "        tri_color = 'white'\n",
    "        ax.add_patch(plt.Polygon(tri_vertices, color=tri_color, fill=True))\n",
    "\n",
    "\n",
    "if wind_flag:\n",
    "    time_subselect = xr.DataArray(np.arange(start_index, stop_index), dims=\"time\")\n",
    "    u = u_S_bulk.mean(dim=\"lev\").isel(time=time_subselect).mean(dim=\"time\")\n",
    "    v = v_S_bulk.mean(dim=\"lev\").isel(time=time_subselect).mean(dim=\"time\")\n",
    "    step=1\n",
    "    q = ax.quiver(\n",
    "        lon[::step, ::step],\n",
    "        lat[::step, ::step],\n",
    "        u[::step, ::step],\n",
    "        v[::step, ::step],\n",
    "        angles='xy',\n",
    "        scale_units='xy',\n",
    "        scale=6,\n",
    "        width=0.02,\n",
    "        color=\"green\",\n",
    "        transform=ccrs.PlateCarree()\n",
    "    )\n",
    "    ax.patch.set_alpha(0)\n",
    "    ax.axis('off')\n",
    "\n",
    "if causal_flag:\n",
    "    x_offset = 1\n",
    "    x_pos = AODH0_grid.lon.values\n",
    "    x_pos = list(np.tile(x_pos, (len(x_pos),)) + x_offset)\n",
    "    Y_offset = +1\n",
    "    y_pos = AODH0_grid.lat.values\n",
    "    y_pos = list(np.repeat(y_pos, len(y_pos)) + Y_offset)\n",
    "    y_pos.reverse()\n",
    "    node_positions = {\n",
    "        \"x\": x_pos,\n",
    "        \"y\": y_pos,\n",
    "    }\n",
    "    cmap_N = 256\n",
    "    white_vals = np.ones((cmap_N, 4))\n",
    "    black_vals = np.zeros((cmap_N, 4))\n",
    "    white_cmap = ListedColormap(white_vals)\n",
    "    black_cmap = ListedColormap(black_vals)\n",
    "    tp.plot_graph(\n",
    "        fig_ax=(fig, ax),\n",
    "        val_matrix=val_matrix.round(),\n",
    "        graph=graph,\n",
    "        link_label_fontsize=0.,\n",
    "        arrowhead_size=5,\n",
    "        cmap_edges=white_cmap,\n",
    "        cmap_nodes=\"binary\",\n",
    "        show_colorbar=False,\n",
    "        var_names=[\"\"]*graph.shape[0],\n",
    "        node_pos=node_positions,\n",
    "    )\n",
    "    # Remove link labels which always have \"1\"\n",
    "    for child in ax.get_children():\n",
    "        if isinstance(child, matplotlib.text.Text):\n",
    "            if child.get_text() == \"1\":\n",
    "                Artist.set_visible(child, False)\n",
    "    ax.patch.set_alpha(0)\n",
    "    ax.axis('off')\n",
    "\n",
    "fig.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_name = \"PC-HSW_depThresh{}_lats{}_lons{}_timestart{}_timeend{}.pdf\".format(pval_threshold, lat_bound, lon_bound, start_index, stop_index)\n",
    "fig.savefig(figure_name, bbox_inches='tight')\n",
    "figure_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_min = -10\n",
    "lat_max = 60\n",
    "lon_min = 60\n",
    "lon_max = 150\n",
    "\n",
    "# plot options:\n",
    "heatmap_flag = True\n",
    "coastlines_flag = True\n",
    "wind_flag = True\n",
    "smart_wind_calc = True\n",
    "\n",
    "lat_bound = (lat_min, lat_max)#(-20, 60)#(0, 20)\n",
    "lon_bound = (lon_min, lon_max)#(30, 110)#(90, 110)\n",
    "lat_bounds = [lat_bound]\n",
    "lon_bounds = [lon_bound]\n",
    "lat_diff = lat_bound[1] - lat_bound[0]\n",
    "lon_diff = lon_bound[1] - lon_bound[0]\n",
    "\n",
    "intervals = [(i, i + 7) for i in range(365, 400, 7)]\n",
    "min_start_index = 365\n",
    "max_stop_index = 400\n",
    "clipper = cpp.ClipTransform(dims=[\"lat\", \"lon\"], bounds=[(lat_min, lat_max), (lon_min, lon_max)])\n",
    "spatial_TS_total = np.mean(clipper.fit_transform(ds[\"AOD\"]), axis=(1,2))[min_start_index:max_stop_index].values\n",
    "vmin = spatial_TS_total.min()\n",
    "vmax = spatial_TS_total.max()\n",
    "\n",
    "with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "    clipper = cpp.ClipTransform(dims=[\"lat\", \"lon\"], bounds=[lat_bound, lon_bound])\n",
    "    AODH0_grid = clipper.fit_transform(ds[\"AOD\"])\n",
    "    AODH0_array = AODH0_grid.values\n",
    "    if wind_flag:\n",
    "        # Get wind field data\n",
    "        UH0_grid = clipper.fit_transform(ds[\"U\"])\n",
    "        VH0_grid = clipper.fit_transform(ds[\"V\"])\n",
    "        if smart_wind_calc:\n",
    "            SH0_grid = clipper.fit_transform(ds[\"SULFATE\"])\n",
    "            S_bulk_levs = SH0_grid.mean(dim=[\"lat\", \"lon\", \"time\"]).values\n",
    "            u_S_bulk = UH0_grid.sel(lev=np.where(S_bulk_levs >= 0.000000005)[0], method=\"nearest\")\n",
    "            v_S_bulk = VH0_grid.sel(lev=np.where(S_bulk_levs >= 0.000000005)[0], method=\"nearest\")\n",
    "        else:\n",
    "            u_S_bulk = UH0_grid\n",
    "            v_S_bulk = VH0_grid\n",
    "            \n",
    "\n",
    "        lat = VH0_grid[\"lat\"]\n",
    "        lon = VH0_grid[\"lon\"]\n",
    "        lon, lat = np.meshgrid(lon, lat)\n",
    "        full_lon, full_lat = np.meshgrid(ds[\"U\"][\"lon\"], ds[\"U\"][\"lat\"])\n",
    "\n",
    "for interval in intervals:\n",
    "    start_index = interval[0]\n",
    "    stop_index = interval[1]\n",
    "    ##### PLOTTING #####\n",
    "    fig = plt.figure(figsize=(lon_diff,lat_diff))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "    if heatmap_flag:\n",
    "        heatmap_data = np.mean(AODH0_array[start_index:stop_index, :, :], axis=0)\n",
    "        extent = (lon_bound[0], lon_bound[1], lat_bound[0], lat_bound[1])\n",
    "        ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "        if coastlines_flag:\n",
    "            ax.coastlines(linewidth=15, color='white')\n",
    "        # Generate edges for Lat and Lon arrays\n",
    "        _lat_edges = np.linspace(extent[2], extent[3], heatmap_data.shape[0] + 1)\n",
    "        _lon_edges = np.linspace(extent[0], extent[1], heatmap_data.shape[1] + 1)\n",
    "\n",
    "        # Create meshgrid from edges\n",
    "        Lat_edges, Lon_edges = np.meshgrid(_lat_edges, _lon_edges, indexing='ij')\n",
    "\n",
    "        # Now use Lat_edges and Lon_edges in pcolormesh\n",
    "        hm = ax.pcolormesh(Lon_edges, Lat_edges, heatmap_data, vmin=vmin, cmap=\"cividis\", snap=False, alpha=1, rasterized=False) # vmin=vmin, vmax=vmax,\n",
    "        ax.patch.set_alpha(0)\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Plot triangle over pinatubo\n",
    "    pinatubo_coords = (15, 120)\n",
    "    if lat_bound[0] <= pinatubo_coords[0] <= lat_bound[1]:\n",
    "        if lon_bound[0] <= pinatubo_coords[1] <= lon_bound[1]:\n",
    "            offset = 3\n",
    "            tri_vertices = [\n",
    "                (pinatubo_coords[1], pinatubo_coords[0] + offset),\n",
    "                (pinatubo_coords[1] - offset, pinatubo_coords[0] - offset),\n",
    "                (pinatubo_coords[1] + offset, pinatubo_coords[0] - offset),\n",
    "            ]\n",
    "            tri_color = 'red'\n",
    "            ax.add_patch(plt.Polygon(tri_vertices, color=tri_color, fill=True))\n",
    "\n",
    "\n",
    "    if wind_flag:\n",
    "        time_subselect = xr.DataArray(np.arange(start_index, stop_index), dims=\"time\")\n",
    "        u = u_S_bulk.mean(dim=\"lev\").isel(time=time_subselect).mean(dim=\"time\")\n",
    "        v = v_S_bulk.mean(dim=\"lev\").isel(time=time_subselect).mean(dim=\"time\")\n",
    "        step=5\n",
    "        q = ax.quiver(\n",
    "            lon[::step, ::step],\n",
    "            lat[::step, ::step],\n",
    "            u[::step, ::step],\n",
    "            v[::step, ::step],\n",
    "            angles='xy',\n",
    "            color=\"lime\",\n",
    "            transform=ccrs.PlateCarree()\n",
    "        )\n",
    "        ax.patch.set_alpha(0)\n",
    "        ax.axis('off')\n",
    "\n",
    "\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.savefig(f\"heatmap_{interval}_wind{wind_flag}.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot options:\n",
    "heatmap_flag = True\n",
    "coastlines_flag = True\n",
    "wind_flag = False\n",
    "smart_wind_calc = True\n",
    "\n",
    "lat_min = -30#-10\n",
    "lat_max = 90#60\n",
    "lon_min = -180#60\n",
    "lon_max = 180#150\n",
    "\n",
    "lat_bound = (lat_min, lat_max)#(-20, 60)#(0, 20)\n",
    "lon_bound = (lon_min, lon_max)#(30, 110)#(90, 110)\n",
    "lat_bounds = [lat_bound]\n",
    "lon_bounds = [lon_bound]\n",
    "lat_diff = lat_bound[1] - lat_bound[0]\n",
    "lon_diff = lon_bound[1] - lon_bound[0]\n",
    "\n",
    "# intervals = [(i, i + 7) for i in range(365, 400, 7)]\n",
    "min_start_index = 500\n",
    "max_stop_index = 501#400\n",
    "intervals = [(min_start_index, max_stop_index)]\n",
    "clipper = cpp.ClipTransform(dims=[\"lat\", \"lon\"], bounds=[(lat_min, lat_max), (lon_min, lon_max)])\n",
    "spatial_TS_total = np.mean(clipper.fit_transform(ds[\"AOD\"]), axis=(1,2))[min_start_index:max_stop_index].values\n",
    "vmin = spatial_TS_total.min()\n",
    "vmax = spatial_TS_total.max()\n",
    "\n",
    "with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "    clipper = cpp.ClipTransform(dims=[\"lat\", \"lon\"], bounds=[lat_bound, lon_bound])\n",
    "    AODH0_grid = clipper.fit_transform(ds[\"AOD\"])\n",
    "    AODH0_array = AODH0_grid.values\n",
    "    if wind_flag:\n",
    "        # Get wind field data\n",
    "        UH0_grid = clipper.fit_transform(ds[\"U\"])\n",
    "        VH0_grid = clipper.fit_transform(ds[\"V\"])\n",
    "        if smart_wind_calc:\n",
    "            SH0_grid = clipper.fit_transform(ds[\"SULFATE\"])\n",
    "            S_bulk_levs = SH0_grid.mean(dim=[\"lat\", \"lon\", \"time\"]).values\n",
    "            u_S_bulk = UH0_grid.sel(lev=np.where(S_bulk_levs >= 0.000000005)[0], method=\"nearest\")\n",
    "            v_S_bulk = VH0_grid.sel(lev=np.where(S_bulk_levs >= 0.000000005)[0], method=\"nearest\")\n",
    "        else:\n",
    "            u_S_bulk = UH0_grid\n",
    "            v_S_bulk = VH0_grid\n",
    "            \n",
    "\n",
    "        lat = VH0_grid[\"lat\"]\n",
    "        lon = VH0_grid[\"lon\"]\n",
    "        lon, lat = np.meshgrid(lon, lat)\n",
    "        full_lon, full_lat = np.meshgrid(ds[\"U\"][\"lon\"], ds[\"U\"][\"lat\"])\n",
    "\n",
    "for interval in intervals:\n",
    "    start_index = interval[0]\n",
    "    stop_index = interval[1]\n",
    "    ##### PLOTTING #####\n",
    "    fig = plt.figure(figsize=(lon_diff,lat_diff))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.AzimuthalEquidistant(central_longitude=85.0, central_latitude=90.0, false_easting=0.0, false_northing=0.0, globe=None))\n",
    "    if heatmap_flag:\n",
    "        heatmap_data = np.mean(AODH0_array[start_index:stop_index, :, :], axis=0)\n",
    "        extent = (lon_bound[0], lon_bound[1], lat_bound[0], lat_bound[1])\n",
    "        ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "        if coastlines_flag:\n",
    "            ax.coastlines(linewidth=15, color='white')\n",
    "        # Generate edges for Lat and Lon arrays\n",
    "        _lat_edges = np.linspace(extent[2], extent[3], heatmap_data.shape[0] + 1)\n",
    "        _lon_edges = np.linspace(extent[0], extent[1], heatmap_data.shape[1] + 1)\n",
    "\n",
    "        # Create meshgrid from edges\n",
    "        Lat_edges, Lon_edges = np.meshgrid(_lat_edges, _lon_edges, indexing='ij')\n",
    "\n",
    "        # Now use Lat_edges and Lon_edges in pcolormesh\n",
    "        hm = ax.pcolormesh(Lon_edges, Lat_edges, heatmap_data, vmin=vmin, cmap=\"cividis\", snap=False, alpha=1, rasterized=False, transform=ccrs.PlateCarree()) # vmin=vmin, vmax=vmax,\n",
    "        ax.patch.set_alpha(0)\n",
    "        ax.axis('off')\n",
    "\n",
    "    if wind_flag:\n",
    "        time_subselect = xr.DataArray(np.arange(start_index, stop_index), dims=\"time\")\n",
    "        u = u_S_bulk.mean(dim=\"lev\").isel(time=time_subselect).mean(dim=\"time\").values\n",
    "        v = v_S_bulk.mean(dim=\"lev\").isel(time=time_subselect).mean(dim=\"time\").values\n",
    "        step=10\n",
    "        # start=4\n",
    "        # end=-4\n",
    "        q = ax.quiver(\n",
    "            lon[::step, ::step],\n",
    "            lat[::step, ::step],\n",
    "            u[::step, ::step],\n",
    "            v[::step, ::step],\n",
    "            angles='xy',\n",
    "            color=\"lime\",\n",
    "            transform=ccrs.PlateCarree()\n",
    "        )\n",
    "        ax.patch.set_alpha(0)\n",
    "        ax.axis('off')\n",
    "\n",
    "\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.savefig(f\"heatmap_{interval}_wind{wind_flag}_AzimuthalEquidistant.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cividis = plt.cm.get_cmap('cividis', 256)  # Get the cividis colormap\n",
    "darkest_color = cividis(0)  # Darkest color at the start of the colormap\n",
    "brightest_color = cividis(255)  # Brightest color at the end of the colormap\n",
    "\n",
    "# Set the background color of the figure\n",
    "plt.rcParams['figure.facecolor'] = darkest_color\n",
    "plt.rcParams['axes.facecolor'] = darkest_color\n",
    "plt.rcParams['savefig.facecolor'] = darkest_color\n",
    "\n",
    "# Mt. Pinatubo's coordinates\n",
    "pinatubo_lat = 15\n",
    "pinatubo_lon = 120\n",
    "\n",
    "# Find the indices of the grid cell closest to Mt. Pinatubo's coordinates\n",
    "lat_idx = np.abs(AODH0_grid.lat - pinatubo_lat).argmin().item()  # Use .item() to get a pure Python int\n",
    "lon_idx = np.abs(AODH0_grid.lon - pinatubo_lon).argmin().item()  # Use .item() to get a pure Python int\n",
    "\n",
    "# Define the size of the square to extract\n",
    "square_size = 10  # Example size of the square\n",
    "\n",
    "# Calculate indices for the square centered around Mt. Pinatubo\n",
    "lat_indices = slice(max(0, lat_idx - square_size // 2), lat_idx + square_size // 2 + 1)\n",
    "lon_indices = slice(max(0, lon_idx - square_size // 2), lon_idx + square_size // 2 + 1)\n",
    "\n",
    "# Extract the subset\n",
    "subset = AODH0_grid.isel(lat=lat_indices, lon=lon_indices)\n",
    "\n",
    "# Create a figure object\n",
    "fig, axes = plt.subplots(square_size, square_size, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "# Adjust the loop to invert the latitude order and select the desired time steps\n",
    "for i in range(square_size):\n",
    "    for j in range(square_size):\n",
    "        # Invert the latitude index by using (square_size - 1 - i) instead of i\n",
    "        ax = axes[square_size - 1 - i, j]\n",
    "        \n",
    "        ax.plot(subset.isel(lat=i, lon=j, time=slice(min_start_index, max_stop_index)), color=brightest_color)  # Use slice for time steps\n",
    "        ax.grid(True)\n",
    "        ax.set_xticklabels([])  # Hide x-axis labels\n",
    "        ax.set_yticklabels([])  # Hide y-axis labels\n",
    "        ax.set_xticks([])  # Remove x-axis ticks\n",
    "        ax.set_yticks([])  # Remove y-axis ticks\n",
    "        # Add border around each plot\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('white')\n",
    "            spine.set_linewidth(1)\n",
    "\n",
    "# Remove spacing between subplots\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "# Add ellipses (three dots) to imply more data beyond the edges, with increased font size and rotation for top and bottom\n",
    "ellipse_fontsize = 20  # Increased font size\n",
    "for ax in axes[:, 0]:  # Left edge\n",
    "    ax.text(-0.2, 0.5, '...', transform=ax.transAxes, ha='right', va='center', fontsize=ellipse_fontsize, color=\"white\")\n",
    "for ax in axes[:, -1]:  # Right edge\n",
    "    ax.text(1.2, 0.5, '...', transform=ax.transAxes, ha='left', va='center', fontsize=ellipse_fontsize, color=\"white\")\n",
    "for ax in axes[0, :]:  # Top edge\n",
    "    ax.text(0.5, 1.2, '...', transform=ax.transAxes, ha='center', va='bottom', fontsize=ellipse_fontsize, rotation='vertical', color=\"white\")\n",
    "for ax in axes[-1, :]:  # Bottom edge\n",
    "    ax.text(0.5, -0.2, '...', transform=ax.transAxes, ha='center', va='top', fontsize=ellipse_fontsize, rotation='vertical', color=\"white\")\n",
    "\n",
    "plt.show()\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the figure to a PDF file using the Figure object's savefig method\n",
    "fig.savefig('aod_grid_visualization.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cldera_causal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
